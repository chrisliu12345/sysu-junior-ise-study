\documentclass[10pt,onecolumn,letterpaper]{article}

\usepackage{xeCJK}
\setCJKmainfont[AutoFakeSlant=0.25]{Noto Sans Mono CJK SC}
\setCJKsansfont[AutoFakeSlant=0.25]{Noto Sans Mono CJK SC}
\setCJKmonofont[AutoFakeSlant=0.25]{Noto Sans Mono CJK SC}

\usepackage{cite}

\begin{document}
    \title{联邦学习中的通信优化}
    \author{17363092 叶茂青，17363079 王珺}

    \maketitle
    \begin{abstract}
        联邦学习的提出使得用户可以在保证隐私的同时贡献自己的数据，但高昂的通信成本限制了联邦学习的应用，本文总结了联邦学习针对网络梯度传输所做的各种优化。
    \end{abstract}
    
    
    \section{TODO}
    problem that the research addresses

    background information and relevant references

    elements that validate the level of innovation of the research

    conceptual model, methodology or procedure that the research takes into consideration

    analysis and interpretation of the results achieved

    strengths and weaknesses of the research, the insights demonstrated

    implications for further research


    \section{联邦学习的介绍}
    联邦学习的数学模型描述在2016年由McMahan et al.\cite{McMahan2016}提出，McMahan et al.同时也提出了联邦学习区别于分布式学习的四大难点：
    \begin{itemize}
        \item Non-IID
        \item Unbalanced
        \item Massively distributed
        \item Limited communication
    \end{itemize}
    由于联邦学习的应用场景中，客户端多为个人设备，通信成本高且通信质量也不能保证


    \section{梯度压缩}
    针对
    \begin{table}[htb]
    \begin{tabular}{|l|l|l|}
    \hline
                            & Works        \\ \hline
    Gradient quantization   & \begin{tabular}[c]{@{}l@{}}Wen et al.\cite{Wen}\\ Seide et al.\cite{Seide2014}\\ Zhou et al.\cite{Zhou}\end{tabular}                                         \\ \hline
    Gradient sparsification & \begin{tabular}[c]{@{}l@{}}Storm\cite{International}\\ Dryden et al.\cite{Dryden2016}\\ Aji \& Heafielf\cite{Aji2017}\\ Chen et al.\cite{Chen}\end{tabular} \\ \hline
    \end{tabular}
    \end{table}

    \subsection{Gradient quantization}
    Gradient quantization的思路主要是将原来32位浮点数存储的梯度信息量化为更低准确度的存储表示。这方面的研究有Seide et al.\cite{Seide2014}提出的1-bit SGD、Alistarh et al.\cite{Alistarh}提出的QSGD、Wen et al.\cite{Wen}提出的TernGrad等

    \subsection{Gradient sparsification}
    Gradient sparsification的思路主要是xxx


    {\small
        \bibliographystyle{IEEEtran} 
        \bibliography{assignment1.bib}
    }
\end{document}